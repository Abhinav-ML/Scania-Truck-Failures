{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                Sensor Component Failure Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Problem statement.\n",
    "\n",
    "**Data:** Sensor Data\n",
    "\n",
    "**Problem statement :**\n",
    "- The system in focus is the Air Pressure system (APS) which generates pressurized air that are utilized in various functions in a truck, such as braking and gear changes. The datasets positive class corresponds to component failures for a specific component of the APS system. The negative class corresponds to trucks with failures for components not related to the APS system.\n",
    "\n",
    "- The problem is to reduce the cost due to unnecessary repairs. So it is required to minimize the false predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|True class | Positive | Negative | |\n",
    "| ----------- | ----------- |   |  |\n",
    "|<b>Predicted class</b>||| |\n",
    "| Positive      |   -       | cost_1  |    |\n",
    "| Negative   | cost_2        |  | |\n",
    "\n",
    "\n",
    "Cost 1 = 10 and Cost 2 = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The total cost of a prediction model the sum of `Cost_1` multiplied by the number of Instances with type 1 failure and `Cost_2` with the number of instances with type 2 failure, resulting in a `Total_cost`. In this case `Cost_1` refers to the cost that an unnessecary check needs to be done by an mechanic at an workshop, while `Cost_2` refer to the cost of missing a faulty truck, which may cause a breakdown. \n",
    "- `Total_cost = Cost_1 * No_Instances + Cost_2 * No_Instances.`\n",
    "\n",
    "- From the above problem statement we could observe that, we have to reduce false positives and false negatives. More importantly we have to **reduce false negatives, since cost incurred due to false negative is 50 times higher than the false positives.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges and other objectives\n",
    "\n",
    "- Need to Handle many Null values in almost all columns\n",
    "- No low-latency requirement.\n",
    "- Interpretability is not important.\n",
    "- misclassification leads the unecessary repair costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score,roc_curve,confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import  train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file\n",
    "df = pd.read_csv('aps_failure_training_reduced.csv', na_values=\"na\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 171)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check rows and columns of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    4909\n",
       "pos      91\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check unique values of target varaible\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 170 numerical features : ['aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000', 'ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009', 'ah_000', 'ai_000', 'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000', 'ap_000', 'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000', 'av_000', 'ax_000', 'ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009', 'az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007', 'az_008', 'az_009', 'ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004', 'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'bb_000', 'bc_000', 'bd_000', 'be_000', 'bf_000', 'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'bs_000', 'bt_000', 'bu_000', 'bv_000', 'bx_000', 'by_000', 'bz_000', 'ca_000', 'cb_000', 'cc_000', 'cd_000', 'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', 'cj_000', 'ck_000', 'cl_000', 'cm_000', 'cn_000', 'cn_001', 'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008', 'cn_009', 'co_000', 'cp_000', 'cq_000', 'cr_000', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006', 'cs_007', 'cs_008', 'cs_009', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000', 'dd_000', 'de_000', 'df_000', 'dg_000', 'dh_000', 'di_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000', 'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000', 'dv_000', 'dx_000', 'dy_000', 'dz_000', 'ea_000', 'eb_000', 'ec_00', 'ed_000', 'ee_000', 'ee_001', 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009', 'ef_000', 'eg_000']\n",
      "\n",
      "We have 1 categorical features : ['class']\n"
     ]
    }
   ],
   "source": [
    "# define numerical & categorical columns\n",
    "numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "categorical_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "\n",
    "# print columns\n",
    "print('We have {} numerical features : {}'.format(len(numeric_features), numeric_features))\n",
    "print('\\nWe have {} categorical features : {}'.format(len(categorical_features), categorical_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As this is a Sensor data. Interpretation of the data is not required "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Missing values count for each column\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "missing = df.isna().sum().div(df.shape[0]).mul(100).to_frame().sort_values(by=0, ascending = False)\n",
    "\n",
    "ax.bar(missing.index, missing.values.T[0])\n",
    "plt.xticks([])\n",
    "plt.ylabel(\"Percentage missing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Columns which has more than 70% of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>br_000</th>\n",
       "      <td>82.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bq_000</th>\n",
       "      <td>80.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp_000</th>\n",
       "      <td>79.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_000</th>\n",
       "      <td>76.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cr_000</th>\n",
       "      <td>76.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo_000</th>\n",
       "      <td>76.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bn_000</th>\n",
       "      <td>72.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "br_000  82.10\n",
       "bq_000  80.86\n",
       "bp_000  79.20\n",
       "ab_000  76.98\n",
       "cr_000  76.98\n",
       "bo_000  76.64\n",
       "bn_000  72.62"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dropping columns which has more than 70% of missing values\n",
    "dropcols = missing[missing[0]>70]\n",
    "dropcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(list(dropcols.index), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 164)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of the dataset after dropping columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of total missing cells in the data 5.412195121951219%\n"
     ]
    }
   ],
   "source": [
    "missing_values_count= df.isnull().sum()\n",
    "total_cells = np.product(df.shape)\n",
    "total_missing = missing_values_count.sum()\n",
    "\n",
    "# percent of data that is missing\n",
    "print(f\"Percentage of total missing cells in the data {(total_missing/total_cells) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of unique values in Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 91, Negative: 4909\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos = df[df['class']=='pos'].shape[0]\n",
    "neg = df[df['class']=='neg'].shape[0]\n",
    "print(\"Positive: \" + str(pos) + \", Negative: \" + str(neg))\n",
    "sns.catplot(data=df, x=\"class\", kind=\"count\", palette=\"winter_r\", alpha=.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Report**\n",
    "- The target classes are highly imbalanced\n",
    "- Class imbalance is a scenario that arises when we have unequal distribution of class in a dataset i.e. the no. of data points in the negative class (majority class) very large compared to that of the positive class (minority class)\n",
    "- If the imbalanced data is not treated beforehand, then this will degrade the performance of the classifier model. \n",
    "- Hence we should handle imbalanced data with certain methods.\n",
    "\n",
    "**How to handle Imbalance Data ?**\n",
    "\n",
    "- Resampling data is one of the most commonly preferred approaches to deal with an imbalanced dataset. There are broadly two types of methods for this i) Undersampling ii) Oversampling. In most cases, oversampling is preferred over undersampling techniques. The reason being, in undersampling we tend to remove instances from data that may be carrying some important information.\n",
    "- **SMOTE:** Synthetic Minority Oversampling Technique\n",
    "- SMOTE is an oversampling technique where the synthetic samples are generated for the minority class.\n",
    "- Hybridization techniques involve combining both undersampling and oversampling techniques. This is done to optimize the performance of classifier models for the samples created as part of these techniques.\n",
    "- It only duplicates the data and it won't add and new information. Hence we look at some different techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Functions for model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(true, predicted):\n",
    "    '''\n",
    "    This function takes in true values and predicted values\n",
    "    Returns: Accuracy, F1-Score, Precision, Recall, Roc-auc Score\n",
    "    '''\n",
    "    acc = accuracy_score(true, predicted) # Calculate Accuracy\n",
    "    f1 = f1_score(true, predicted) # Calculate F1-score\n",
    "    precision = precision_score(true, predicted) # Calculate Precision\n",
    "    recall = recall_score(true, predicted)  # Calculate Recall\n",
    "    roc_auc = roc_auc_score(true, predicted) #Calculate Roc\n",
    "    return acc, f1 , precision, recall, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cost of the model as per data description\n",
    "def total_cost(y_true, y_pred):\n",
    "    '''\n",
    "    This function takes y_ture, y_predicted, and prints Total cost due to misclassification\n",
    "   \n",
    "    '''\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    cost = 10*fp + 500*fn\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function which can evaluate models and return a report \n",
    "def evaluate_models(X, y, models):\n",
    "    '''\n",
    "    This function takes in X and y and models dictionary as input\n",
    "    It splits the data into Train Test split\n",
    "    Iterates through the given model dictionary and evaluates the metrics\n",
    "    Returns: Dataframe which contains report of all models metrics with cost\n",
    "    '''\n",
    "    # separate dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "    cost_list=[]\n",
    "    models_list = []\n",
    "    accuracy_list = []\n",
    "    \n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train) # Train model\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        # Training set performance\n",
    "        model_train_accuracy, model_train_f1,model_train_precision,\\\n",
    "        model_train_recall,model_train_rocauc_score=evaluate_clf(y_train ,y_train_pred)\n",
    "        train_cost = total_cost(y_train, y_train_pred)\n",
    "\n",
    "\n",
    "        # Test set performance\n",
    "        model_test_accuracy,model_test_f1,model_test_precision,\\\n",
    "        model_test_recall,model_test_rocauc_score=evaluate_clf(y_test, y_test_pred)\n",
    "        test_cost = total_cost(y_test, y_test_pred)\n",
    "\n",
    "        print(list(models.keys())[i])\n",
    "        models_list.append(list(models.keys())[i])\n",
    "\n",
    "        print('Model performance for Training set')\n",
    "        print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_train_f1)) \n",
    "        print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "        print(f'- COST: {train_cost}.')\n",
    "\n",
    "        print('----------------------------------')\n",
    "\n",
    "        print('Model performance for Test set')\n",
    "        print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "        print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "        print(f'- COST: {test_cost}.')\n",
    "        cost_list.append(test_cost)\n",
    "        print('='*35)\n",
    "        print('\\n')\n",
    "        \n",
    "    report=pd.DataFrame(list(zip(models_list, cost_list)), columns=['Model Name', 'Cost']).sort_values(by=[\"Cost\"])\n",
    "        \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot  distribution of all Independent Numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "\n",
    "plt.figure(figsize=(15, 100))\n",
    "for i, col in enumerate(numeric_features):\n",
    "    plt.subplot(60, 3, i+1)\n",
    "    sns.distplot(x=df[col], color='indianred')\n",
    "    plt.xlabel(col, weight='bold')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Report**\n",
    "- As per the above plot most of the features are not normally distributed.\n",
    "- Transformation of data is not of prime importance since it is a classification problem.\n",
    "- Interpreting each and every column is not necessary as this is sensor data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model on Different experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting X and y for all Experiments\n",
    "X= df.drop('class', axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Manually Encoding Target Variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y= y.replace({'pos': 1, 'neg': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: 1 = KNN Imputer for Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why Robust scaler and not Standard scaler?**\n",
    "- Scaling the data using Robust scaler\n",
    "- Since most of the independent variables are not normally distributed we cannot use Standardscaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why Robust Scaler and not Minmax?** \n",
    "- because most of the feature has outliers. So Minmax will scale data according to Max values which is outlier.\n",
    "- This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit with robust scaler for KNN best K-selection experminet\n",
    "robustscaler = RobustScaler()\n",
    "X1 = robustscaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why KNN Imputer**?\n",
    "- KNNImputer by scikit-learn is a widely used method to impute missing values. It is widely being observed as a replacement for traditional imputation techniques.\n",
    "- KNNImputer helps to impute missing values present in the observations by finding the nearest neighbors with the Euclidean distance matrix.\n",
    "- Here we Iterates through different K values and get accuracy and choose best K values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the optimal n_neighbour value for KNN imputer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors= 1 || accuracy (0.7317)\n",
      "n_neighbors= 3 || accuracy (0.7555)\n",
      "n_neighbors= 5 || accuracy (0.7076)\n",
      "n_neighbors= 7 || accuracy (0.6810)\n",
      "n_neighbors= 9 || accuracy (0.6966)\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "# define imputer\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "strategies = [str(i) for i in [1,3,5,7,9]]\n",
    "for s in strategies:\n",
    "    pipeline = Pipeline(steps=[('i', KNNImputer(n_neighbors=int(s))), ('m', LogisticRegression())])\n",
    "    scores = cross_val_score(pipeline, X1, y, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    results.append(scores)\n",
    "    print('n_neighbors= %s || accuracy (%.4f)' % (s , mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can observe n_neighbors=3 able to produce highest accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline for KNN imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "# Fit the KNN imputer with selected K-value\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=3)),\n",
    "    ('RobustScaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_knn =knn_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **SMOTE+TOMEK** is one of such a hybrid technique that aims to clean overlapping data points for each of the classes distributed in sample space.\n",
    " \n",
    " - This method combines the SMOTE ability to generate synthetic data for minority class and Tomek Links ability to remove the data that are identified as Tomek links from the majority class\n",
    " \n",
    " - To add new data of minority class\n",
    " 1. Choose random data from the minority class.\n",
    " 2. Calculate the distance between the random data and its k nearest neighbors.\n",
    " 3. Multiply the difference with a random number between 0 and 1, then add the result to the minority class as a synthetic sample.\n",
    " 4. Repeat step number 2–3 until the desired proportion of minority class is met.\n",
    " \n",
    " - To remove the tomek links of the majority class\n",
    " 1. Choose random data from the majority class.\n",
    " 2. If the random data’s nearest neighbor is the data from the minority class (i.e. create the Tomek Link), then remove the Tomek Link.\n",
    " \n",
    " - This is method instead of adding duplicate data it synthesises the new data based on the already avalialble classes. Hence we choose this as our imputer method for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority',n_jobs=-1)\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(X_knn, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Default Models in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary which contains models for experiment\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "     \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "     \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit KNN imputed data for models in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9924\n",
      "- F1 score: 0.9925\n",
      "- Precision: 0.9883\n",
      "- Recall: 0.9967\n",
      "- Roc Auc Score: 0.9925\n",
      "- COST: 12330.\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9865\n",
      "- F1 score: 0.9866\n",
      "- Precision: 0.9815\n",
      "- Recall: 0.9917\n",
      "- Roc Auc Score: 0.9865\n",
      "- COST: 30310.\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9839\n",
      "- F1 score: 0.9840\n",
      "- Precision: 0.9803\n",
      "- Recall: 0.9876\n",
      "- Roc Auc Score: 0.9839\n",
      "- COST: 179060.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9844\n",
      "- F1 score: 0.9844\n",
      "- Precision: 0.9813\n",
      "- Recall: 0.9876\n",
      "- Roc Auc Score: 0.9844\n",
      "- COST: 44820.\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.5886\n",
      "- F1 score: 0.6932\n",
      "- Precision: 0.5528\n",
      "- Recall: 0.9291\n",
      "- Roc Auc Score: 0.5885\n",
      "- COST: 1205980.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.5820\n",
      "- F1 score: 0.6896\n",
      "- Precision: 0.5481\n",
      "- Recall: 0.9297\n",
      "- Roc Auc Score: 0.5823\n",
      "- COST: 300230.\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9814\n",
      "- F1 score: 0.9816\n",
      "- Precision: 0.9707\n",
      "- Recall: 0.9927\n",
      "- Roc Auc Score: 0.9814\n",
      "- COST: 110900.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9744\n",
      "- F1 score: 0.9748\n",
      "- Precision: 0.9605\n",
      "- Recall: 0.9894\n",
      "- Roc Auc Score: 0.9744\n",
      "- COST: 39850.\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9962\n",
      "- F1 score: 0.9962\n",
      "- Precision: 0.9935\n",
      "- Recall: 0.9989\n",
      "- Roc Auc Score: 0.9962\n",
      "- COST: 4460.\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9992\n",
      "- F1 score: 0.9992\n",
      "- Precision: 0.9989\n",
      "- Recall: 0.9994\n",
      "- Roc Auc Score: 0.9992\n",
      "- COST: 8800.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9949\n",
      "- F1 score: 0.9949\n",
      "- Precision: 0.9922\n",
      "- Recall: 0.9976\n",
      "- Roc Auc Score: 0.9949\n",
      "- COST: 9050.\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9749\n",
      "- F1 score: 0.9750\n",
      "- Precision: 0.9736\n",
      "- Recall: 0.9763\n",
      "- Roc Auc Score: 0.9749\n",
      "- COST: 339420.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9756\n",
      "- F1 score: 0.9756\n",
      "- Precision: 0.9745\n",
      "- Recall: 0.9767\n",
      "- Roc Auc Score: 0.9756\n",
      "- COST: 83290.\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_knn = evaluate_models(X_res, y_res, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report for KNN Imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>4460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>9050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>12330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>30310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>39850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>44820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>83290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>300230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Name    Cost\n",
       "5           XGBClassifier    4460\n",
       "6  CatBoosting Classifier    9050\n",
       "0           Random Forest   12330\n",
       "1           Decision Tree   30310\n",
       "4  K-Neighbors Classifier   39850\n",
       "2       Gradient Boosting   44820\n",
       "7     AdaBoost Classifier   83290\n",
       "3     Logistic Regression  300230"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "- For the Experiment 1: Knn imputer has XGBoost classifier as the best Model\n",
    "- Proceeding with further experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: 2 = Simple Imputer with Strategy Median "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SimpleImputer is a class in the `sklearn.impute` module that can be used to replace missing values in a dataset, using a variety of input strategies.\n",
    "- Here we use SimpleImputer can also be used to impute multiple columns at once by passing in a list of column names. SimpleImputer will then replace missing values in all of the specified columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "# Fit the Simple imputer with strategy median\n",
    "median_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('RobustScaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit X with median_pipeline\n",
    "X_median = median_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority')\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(X_median, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9917\n",
      "- F1 score: 0.9918\n",
      "- Precision: 0.9866\n",
      "- Recall: 0.9972\n",
      "- Roc Auc Score: 0.9917\n",
      "- COST: 10960.\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9852\n",
      "- F1 score: 0.9854\n",
      "- Precision: 0.9796\n",
      "- Recall: 0.9912\n",
      "- Roc Auc Score: 0.9851\n",
      "- COST: 32460.\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9840\n",
      "- F1 score: 0.9840\n",
      "- Precision: 0.9813\n",
      "- Recall: 0.9867\n",
      "- Roc Auc Score: 0.9840\n",
      "- COST: 190760.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9810\n",
      "- F1 score: 0.9812\n",
      "- Precision: 0.9757\n",
      "- Recall: 0.9868\n",
      "- Roc Auc Score: 0.9809\n",
      "- COST: 48240.\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.6300\n",
      "- F1 score: 0.7147\n",
      "- Precision: 0.5807\n",
      "- Recall: 0.9289\n",
      "- Roc Auc Score: 0.6306\n",
      "- COST: 1181600.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.6264\n",
      "- F1 score: 0.7145\n",
      "- Precision: 0.5813\n",
      "- Recall: 0.9269\n",
      "- Roc Auc Score: 0.6237\n",
      "- COST: 305700.\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9789\n",
      "- F1 score: 0.9791\n",
      "- Precision: 0.9683\n",
      "- Recall: 0.9902\n",
      "- Roc Auc Score: 0.9789\n",
      "- COST: 146570.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9718\n",
      "- F1 score: 0.9724\n",
      "- Precision: 0.9596\n",
      "- Recall: 0.9854\n",
      "- Roc Auc Score: 0.9716\n",
      "- COST: 54430.\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 500.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9951\n",
      "- F1 score: 0.9951\n",
      "- Precision: 0.9920\n",
      "- Recall: 0.9983\n",
      "- Roc Auc Score: 0.9950\n",
      "- COST: 6570.\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9996\n",
      "- F1 score: 0.9996\n",
      "- Precision: 0.9996\n",
      "- Recall: 0.9995\n",
      "- Roc Auc Score: 0.9996\n",
      "- COST: 7110.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9939\n",
      "- F1 score: 0.9939\n",
      "- Precision: 0.9894\n",
      "- Recall: 0.9986\n",
      "- Roc Auc Score: 0.9938\n",
      "- COST: 5760.\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9749\n",
      "- F1 score: 0.9749\n",
      "- Precision: 0.9740\n",
      "- Recall: 0.9757\n",
      "- Roc Auc Score: 0.9749\n",
      "- COST: 346790.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9727\n",
      "- F1 score: 0.9731\n",
      "- Precision: 0.9702\n",
      "- Recall: 0.9760\n",
      "- Roc Auc Score: 0.9727\n",
      "- COST: 87120.\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the models\n",
    "report_median = evaluate_models(X_res, y_res, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report for Simple Imputer with median strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>5760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>6570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>10960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>32460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>48240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>54430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>87120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>305700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Name    Cost\n",
       "6  CatBoosting Classifier    5760\n",
       "5           XGBClassifier    6570\n",
       "0           Random Forest   10960\n",
       "1           Decision Tree   32460\n",
       "2       Gradient Boosting   48240\n",
       "4  K-Neighbors Classifier   54430\n",
       "7     AdaBoost Classifier   87120\n",
       "3     Logistic Regression  305700"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "- For the Experiment 2: Simple imputer with median strategy has Catboost classifier as the best Model\n",
    "- Proceeding with further experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: 3 = MICE for Imputing Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MICE stands for Multivariate Imputation By Chained Equations algorithm\n",
    "- This technique by which we can effortlessly impute missing values in a dataset by looking at data from other columns and trying to estimate the best prediction for each missing value.\n",
    "- `ImputationKernel` Creates a kernel dataset. This dataset can perform MICE on itself, and impute new data from models obtained during MICE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf\n",
    "\n",
    "X_mice = X.copy()\n",
    "kernel = mf.ImputationKernel(\n",
    "  X_mice,\n",
    "  save_all_iterations=True,\n",
    "  random_state=1989\n",
    ")# Run the MICE algorithm for 3 iterations kernel.mice(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mice = kernel.complete_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit robust scaler\n",
    "mice_pipeline = Pipeline(steps=[\n",
    "    ('RobustScaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit X with Mice imputer \n",
    "X_mice= mice_pipeline.fit_transform(X_mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority', n_jobs=-1 )\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(X_mice, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9920\n",
      "- F1 score: 0.9921\n",
      "- Precision: 0.9880\n",
      "- Recall: 0.9962\n",
      "- Roc Auc Score: 0.9920\n",
      "- COST: 14350.\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9822\n",
      "- F1 score: 0.9824\n",
      "- Precision: 0.9783\n",
      "- Recall: 0.9865\n",
      "- Roc Auc Score: 0.9822\n",
      "- COST: 49040.\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9854\n",
      "- F1 score: 0.9854\n",
      "- Precision: 0.9825\n",
      "- Recall: 0.9884\n",
      "- Roc Auc Score: 0.9854\n",
      "- COST: 166940.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9813\n",
      "- F1 score: 0.9815\n",
      "- Precision: 0.9772\n",
      "- Recall: 0.9858\n",
      "- Roc Auc Score: 0.9813\n",
      "- COST: 51620.\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.6272\n",
      "- F1 score: 0.7191\n",
      "- Precision: 0.5766\n",
      "- Recall: 0.9551\n",
      "- Roc Auc Score: 0.6276\n",
      "- COST: 826010.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.6200\n",
      "- F1 score: 0.7160\n",
      "- Precision: 0.5729\n",
      "- Recall: 0.9545\n",
      "- Roc Auc Score: 0.6187\n",
      "- COST: 210090.\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9792\n",
      "- F1 score: 0.9795\n",
      "- Precision: 0.9677\n",
      "- Recall: 0.9915\n",
      "- Roc Auc Score: 0.9792\n",
      "- COST: 128270.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9704\n",
      "- F1 score: 0.9710\n",
      "- Precision: 0.9566\n",
      "- Recall: 0.9858\n",
      "- Roc Auc Score: 0.9703\n",
      "- COST: 53150.\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9959\n",
      "- F1 score: 0.9960\n",
      "- Precision: 0.9928\n",
      "- Recall: 0.9991\n",
      "- Roc Auc Score: 0.9959\n",
      "- COST: 3510.\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9996\n",
      "- F1 score: 0.9996\n",
      "- Precision: 0.9997\n",
      "- Recall: 0.9995\n",
      "- Roc Auc Score: 0.9996\n",
      "- COST: 6580.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9940\n",
      "- F1 score: 0.9941\n",
      "- Precision: 0.9903\n",
      "- Recall: 0.9979\n",
      "- Roc Auc Score: 0.9940\n",
      "- COST: 8190.\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9758\n",
      "- F1 score: 0.9758\n",
      "- Precision: 0.9769\n",
      "- Recall: 0.9746\n",
      "- Roc Auc Score: 0.9758\n",
      "- COST: 361950.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9742\n",
      "- F1 score: 0.9743\n",
      "- Precision: 0.9746\n",
      "- Recall: 0.9740\n",
      "- Roc Auc Score: 0.9742\n",
      "- COST: 93290.\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the models\n",
    "report_mice = evaluate_models(X_res, y_res, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report for MICE Imputer algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>3510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>8190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>14350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>49040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>51620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>53150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>93290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>210090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Name    Cost\n",
       "5           XGBClassifier    3510\n",
       "6  CatBoosting Classifier    8190\n",
       "0           Random Forest   14350\n",
       "1           Decision Tree   49040\n",
       "2       Gradient Boosting   51620\n",
       "4  K-Neighbors Classifier   53150\n",
       "7     AdaBoost Classifier   93290\n",
       "3     Logistic Regression  210090"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_mice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "- For the Experiment 3: Mice imputer has XGBoost classifier as the best Model\n",
    "- Proceeding with further experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: 4 = Simple Imputer with Strategy Constant "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another strategy which can be used is replacing missing values with a fixed (constant) value.\n",
    "- To do this, specify “constant” for strategy and specify the fill value using the fill_value parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with simple imputer with strategy constant and fill value 0\n",
    "constant_pipeline = Pipeline(steps=[\n",
    "    ('Imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('RobustScaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_const =constant_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority', n_jobs=-1 )\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(X_const, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9933\n",
      "- F1 score: 0.9933\n",
      "- Precision: 0.9894\n",
      "- Recall: 0.9973\n",
      "- Roc Auc Score: 0.9933\n",
      "- COST: 10250.\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9882\n",
      "- F1 score: 0.9883\n",
      "- Precision: 0.9831\n",
      "- Recall: 0.9936\n",
      "- Roc Auc Score: 0.9882\n",
      "- COST: 23700.\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9829\n",
      "- F1 score: 0.9829\n",
      "- Precision: 0.9799\n",
      "- Recall: 0.9860\n",
      "- Roc Auc Score: 0.9829\n",
      "- COST: 201670.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9806\n",
      "- F1 score: 0.9807\n",
      "- Precision: 0.9774\n",
      "- Recall: 0.9841\n",
      "- Roc Auc Score: 0.9806\n",
      "- COST: 57600.\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.6710\n",
      "- F1 score: 0.7482\n",
      "- Precision: 0.6057\n",
      "- Recall: 0.9784\n",
      "- Roc Auc Score: 0.6712\n",
      "- COST: 481530.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.6702\n",
      "- F1 score: 0.7487\n",
      "- Precision: 0.6058\n",
      "- Recall: 0.9800\n",
      "- Roc Auc Score: 0.6693\n",
      "- COST: 115350.\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9803\n",
      "- F1 score: 0.9805\n",
      "- Precision: 0.9682\n",
      "- Recall: 0.9932\n",
      "- Roc Auc Score: 0.9803\n",
      "- COST: 105130.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9750\n",
      "- F1 score: 0.9754\n",
      "- Precision: 0.9626\n",
      "- Recall: 0.9885\n",
      "- Roc Auc Score: 0.9749\n",
      "- COST: 43200.\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 500.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9964\n",
      "- F1 score: 0.9965\n",
      "- Precision: 0.9936\n",
      "- Recall: 0.9993\n",
      "- Roc Auc Score: 0.9964\n",
      "- COST: 2950.\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9991\n",
      "- F1 score: 0.9991\n",
      "- Precision: 0.9991\n",
      "- Recall: 0.9992\n",
      "- Roc Auc Score: 0.9991\n",
      "- COST: 11750.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9961\n",
      "- F1 score: 0.9961\n",
      "- Precision: 0.9934\n",
      "- Recall: 0.9989\n",
      "- Roc Auc Score: 0.9961\n",
      "- COST: 4470.\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9735\n",
      "- F1 score: 0.9735\n",
      "- Precision: 0.9731\n",
      "- Recall: 0.9739\n",
      "- Roc Auc Score: 0.9735\n",
      "- COST: 374050.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9734\n",
      "- F1 score: 0.9735\n",
      "- Precision: 0.9745\n",
      "- Recall: 0.9724\n",
      "- Roc Auc Score: 0.9734\n",
      "- COST: 98790.\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training the models\n",
    "report_const = evaluate_models(X_res, y_res, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report for Simple Imputer with Constant strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>2950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>4470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>10250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>23700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>43200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>57600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>98790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>115350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Name    Cost\n",
       "5           XGBClassifier    2950\n",
       "6  CatBoosting Classifier    4470\n",
       "0           Random Forest   10250\n",
       "1           Decision Tree   23700\n",
       "4  K-Neighbors Classifier   43200\n",
       "2       Gradient Boosting   57600\n",
       "7     AdaBoost Classifier   98790\n",
       "3     Logistic Regression  115350"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_const"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "- For the Experiment 4: Simple imputer with constant strategy has XGBoost classifier as the best Model\n",
    "- Proceeding with further experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: 5 = Simple Imputer with Strategy Mean \n",
    "\n",
    "- Another strategy which can be used is replacing missing values with mean\n",
    "- Here we replace the missing values with the mean of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with Simple imputer with strategy mean\n",
    "mean_pipeline = Pipeline(steps=[\n",
    "    ('Imputer', SimpleImputer(strategy='mean')),\n",
    "    ('RobustScaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = mean_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority' , n_jobs=-1)\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(X_mean, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9945\n",
      "- F1 score: 0.9945\n",
      "- Precision: 0.9910\n",
      "- Recall: 0.9980\n",
      "- Roc Auc Score: 0.9944\n",
      "- COST: 7640.\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 0.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9893\n",
      "- F1 score: 0.9894\n",
      "- Precision: 0.9867\n",
      "- Recall: 0.9921\n",
      "- Roc Auc Score: 0.9893\n",
      "- COST: 28940.\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9839\n",
      "- F1 score: 0.9839\n",
      "- Precision: 0.9810\n",
      "- Recall: 0.9868\n",
      "- Roc Auc Score: 0.9839\n",
      "- COST: 190870.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9812\n",
      "- F1 score: 0.9813\n",
      "- Precision: 0.9771\n",
      "- Recall: 0.9855\n",
      "- Roc Auc Score: 0.9812\n",
      "- COST: 52630.\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9533\n",
      "- F1 score: 0.9524\n",
      "- Precision: 0.9711\n",
      "- Recall: 0.9344\n",
      "- Roc Auc Score: 0.9533\n",
      "- COST: 930810.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9539\n",
      "- F1 score: 0.9532\n",
      "- Precision: 0.9694\n",
      "- Recall: 0.9376\n",
      "- Roc Auc Score: 0.9539\n",
      "- COST: 222090.\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9868\n",
      "- F1 score: 0.9869\n",
      "- Precision: 0.9754\n",
      "- Recall: 0.9988\n",
      "- Roc Auc Score: 0.9868\n",
      "- COST: 24580.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9837\n",
      "- F1 score: 0.9840\n",
      "- Precision: 0.9701\n",
      "- Recall: 0.9983\n",
      "- Roc Auc Score: 0.9837\n",
      "- COST: 8170.\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 1.0000\n",
      "- F1 score: 1.0000\n",
      "- Precision: 1.0000\n",
      "- Recall: 1.0000\n",
      "- Roc Auc Score: 1.0000\n",
      "- COST: 500.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9962\n",
      "- F1 score: 0.9962\n",
      "- Precision: 0.9936\n",
      "- Recall: 0.9987\n",
      "- Roc Auc Score: 0.9962\n",
      "- COST: 4950.\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9993\n",
      "- F1 score: 0.9993\n",
      "- Precision: 0.9991\n",
      "- Recall: 0.9994\n",
      "- Roc Auc Score: 0.9993\n",
      "- COST: 9240.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9947\n",
      "- F1 score: 0.9948\n",
      "- Precision: 0.9915\n",
      "- Recall: 0.9980\n",
      "- Roc Auc Score: 0.9947\n",
      "- COST: 7600.\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9746\n",
      "- F1 score: 0.9746\n",
      "- Precision: 0.9754\n",
      "- Recall: 0.9737\n",
      "- Roc Auc Score: 0.9746\n",
      "- COST: 376900.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9746\n",
      "- F1 score: 0.9746\n",
      "- Precision: 0.9745\n",
      "- Recall: 0.9748\n",
      "- Roc Auc Score: 0.9746\n",
      "- COST: 90800.\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training all models\n",
    "report_mean = evaluate_models(X_res, y_res, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report for Simple imputer with strategy mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>4950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>7600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>7640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>8170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>28940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>52630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>90800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>222090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Name    Cost\n",
       "5           XGBClassifier    4950\n",
       "6  CatBoosting Classifier    7600\n",
       "0           Random Forest    7640\n",
       "4  K-Neighbors Classifier    8170\n",
       "1           Decision Tree   28940\n",
       "2       Gradient Boosting   52630\n",
       "7     AdaBoost Classifier   90800\n",
       "3     Logistic Regression  222090"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment: 5 = Principle component analysis with imputing median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Principal component analysis is a technique for feature extraction — so it combines our input variables in a specific way, then we can drop the “least important” variables while still retaining the most valuable parts of all of the variables! \n",
    "- As the dataset has 164 columns we can try PCA and check our metrics Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipeline = Pipeline(steps=[\n",
    "    ('Imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('RobustScaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying PCA\n",
    "from sklearn.decomposition import PCA\n",
    "var_ratio={}\n",
    "for n in range(2,150):\n",
    "    pc=PCA(n_components=n)\n",
    "    df_pca=pc.fit(X_pca)\n",
    "    var_ratio[n]=sum(df_pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variance Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting variance ratio\n",
    "pd.Series(var_ratio).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kneed algorithm to find the elbow point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 360x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knee Locator k = 18\n"
     ]
    }
   ],
   "source": [
    "from kneed import KneeLocator\n",
    "\n",
    "i = np.arange(len(var_ratio))\n",
    "variance_ratio= list(var_ratio.values())\n",
    "components=  list(var_ratio.keys())\n",
    "knee = KneeLocator(i, variance_ratio, S=1, curve='concave', interp_method='polynomial')\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "knee.plot_knee()\n",
    "plt.xlabel(\"Points\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.show()\n",
    "k= components[knee.knee]\n",
    "print('Knee Locator k =', k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing the dimensions of the data \n",
    "pca_final=PCA(n_components=18,random_state=42).fit(X_res)\n",
    "\n",
    "reduced=pca_final.fit_transform(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority', n_jobs=-1)\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(reduced, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9986\n",
      "- F1 score: 0.9986\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9972\n",
      "- Roc Auc Score: 0.9986\n",
      "- COST: 39500.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9830\n",
      "- F1 score: 0.9831\n",
      "- Precision: 0.9787\n",
      "- Recall: 0.9876\n",
      "- Roc Auc Score: 0.9830\n",
      "- COST: 45010.\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9986\n",
      "- F1 score: 0.9986\n",
      "- Precision: 1.0000\n",
      "- Recall: 0.9972\n",
      "- Roc Auc Score: 0.9986\n",
      "- COST: 39500.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9741\n",
      "- F1 score: 0.9743\n",
      "- Precision: 0.9708\n",
      "- Recall: 0.9778\n",
      "- Roc Auc Score: 0.9741\n",
      "- COST: 80060.\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9416\n",
      "- F1 score: 0.9414\n",
      "- Precision: 0.9442\n",
      "- Recall: 0.9385\n",
      "- Roc Auc Score: 0.9416\n",
      "- COST: 874480.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9381\n",
      "- F1 score: 0.9380\n",
      "- Precision: 0.9440\n",
      "- Recall: 0.9320\n",
      "- Roc Auc Score: 0.9382\n",
      "- COST: 242380.\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8516\n",
      "- F1 score: 0.8313\n",
      "- Precision: 0.9618\n",
      "- Recall: 0.7319\n",
      "- Roc Auc Score: 0.8515\n",
      "- COST: 3753110.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8490\n",
      "- F1 score: 0.8291\n",
      "- Precision: 0.9597\n",
      "- Recall: 0.7298\n",
      "- Roc Auc Score: 0.8494\n",
      "- COST: 950150.\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9722\n",
      "- F1 score: 0.9724\n",
      "- Precision: 0.9640\n",
      "- Recall: 0.9809\n",
      "- Roc Auc Score: 0.9722\n",
      "- COST: 276720.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9652\n",
      "- F1 score: 0.9657\n",
      "- Precision: 0.9565\n",
      "- Recall: 0.9751\n",
      "- Roc Auc Score: 0.9652\n",
      "- COST: 90610.\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9905\n",
      "- F1 score: 0.9905\n",
      "- Precision: 0.9904\n",
      "- Recall: 0.9906\n",
      "- Roc Auc Score: 0.9905\n",
      "- COST: 133670.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9788\n",
      "- F1 score: 0.9790\n",
      "- Precision: 0.9746\n",
      "- Recall: 0.9835\n",
      "- Roc Auc Score: 0.9788\n",
      "- COST: 59800.\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9824\n",
      "- F1 score: 0.9824\n",
      "- Precision: 0.9808\n",
      "- Recall: 0.9840\n",
      "- Roc Auc Score: 0.9824\n",
      "- COST: 228370.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9743\n",
      "- F1 score: 0.9745\n",
      "- Precision: 0.9702\n",
      "- Recall: 0.9789\n",
      "- Roc Auc Score: 0.9743\n",
      "- COST: 76110.\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9215\n",
      "- F1 score: 0.9207\n",
      "- Precision: 0.9291\n",
      "- Recall: 0.9126\n",
      "- Roc Auc Score: 0.9215\n",
      "- COST: 1240960.\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.9195\n",
      "- F1 score: 0.9189\n",
      "- Precision: 0.9294\n",
      "- Recall: 0.9086\n",
      "- Roc Auc Score: 0.9196\n",
      "- COST: 325340.\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training all models\n",
    "report_pca = evaluate_models(X_res,y_res, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report for PCA and Mean imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>45010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>59800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>76110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>80060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>90610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>242380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>325340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>950150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Name    Cost\n",
       "0           Random Forest   45010\n",
       "5           XGBClassifier   59800\n",
       "6  CatBoosting Classifier   76110\n",
       "1           Decision Tree   80060\n",
       "4  K-Neighbors Classifier   90610\n",
       "2       Gradient Boosting  242380\n",
       "7     AdaBoost Classifier  325340\n",
       "3     Logistic Regression  950150"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------------+------------+\n",
      "|       Model        |    Imputation_method    | Total_cost |\n",
      "+--------------------+-------------------------+------------+\n",
      "|   XGBClassifier    | Simple Imputer-Constant |    2950    |\n",
      "|   XGBClassifier    |           Mice          |    3510    |\n",
      "|   XGBClassifier    |       Knn-Imputer       |    4460    |\n",
      "|   XGBClassifier    |   Simple Imputer-Mean   |    4950    |\n",
      "| CatBoostClassifier |          Median         |    5760    |\n",
      "|   Random Forest    |           PCA           |   34150    |\n",
      "+--------------------+-------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "pt=PrettyTable()\n",
    "pt.field_names=[\"Model\",\"Imputation_method\",\"Total_cost\"]\n",
    "pt.add_row([\"XGBClassifier\",\"Simple Imputer-Constant\",\"2950\"])\n",
    "pt.add_row([\"XGBClassifier\",\"Mice\",\"3510\"])\n",
    "pt.add_row([\"XGBClassifier\",\"Knn-Imputer\",\"4460\"])\n",
    "pt.add_row([\"XGBClassifier\",\"Simple Imputer-Mean\",\"4950\"])\n",
    "pt.add_row([\"CatBoostClassifier\",\"Median\",\"5760\"])\n",
    "pt.add_row([\"Random Forest\",\"PCA\",\"34150\"])\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Report**\n",
    "- From the final report we can see than XGBClassifier with Simple imputer with strategy constant has performed the best with cost of 2950"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Final model and get reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = XGBClassifier()\n",
    "\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority', n_jobs=-1)\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(X_const, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res,y_res,test_size=0.2,random_state=42)\n",
    "\n",
    "final_model = final_model.fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XGBoost Classifier Accuracy Score (Train) : 0.9999821759589335\n",
      "Final XGBoost Classifier Accuracy Score (Test) : 0.9964351917866818\n"
     ]
    }
   ],
   "source": [
    "print(\"Final XGBoost Classifier Accuracy Score (Train) :\", final_model.score(X_train,y_train))\n",
    "print(\"Final XGBoost Classifier Accuracy Score (Test) :\", accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XGBoost Classifier Cost Metric(Test) : 2950\n"
     ]
    }
   ],
   "source": [
    "print(\"Final XGBoost Classifier Cost Metric(Test) :\",total_cost(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "#plots Confusion matrix\n",
    "plot_confusion_matrix(final_model, X_test, y_test, cmap='Blues', values_format='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The best Model is XGBoost Classifier with 99.6% accuracy and cost of 2950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
